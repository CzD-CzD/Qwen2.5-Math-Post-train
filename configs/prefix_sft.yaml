output_dir: "out/prefix_math"
run_name: "prefix-math"
report_to: "swanlab"

# Prefix-tuning config
num_virtual_tokens: 20
prefix_projection: false

# Train config (mirror full_sft.yaml)
max_length: 1024
num_train_epochs: 5
learning_rate: 5e-5
per_device_train_batch_size: 4
per_device_eval_batch_size: 4
gradient_accumulation_steps: 1

logging_steps: 10
eval_strategy: "steps"
eval_steps: 500

save_strategy: "epoch"

remove_unused_columns: false
bf16: true
fp16: false
dataset_text_field: "text"
